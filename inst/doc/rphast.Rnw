%
% NOTE -- ONLY EDIT THE .Rnw FILE!!!  The .tex file is
% likely to be overwritten.
%
% \VignetteIndexEntry{rphast}
% \VignetteDepends{tools, cluster}
% \VignetteKeywords{Phylogenetics, conservation, Hidden Markov Models}
% \VignettePackage{rphast}

\documentclass[11pt]{article}

\title{Rphast vignettes}
\author{M. J. Hubisz and A. Siepel}
\SweaveOpts{echo=TRUE,fig=TRUE,eval=TRUE,invlude=TRUE,engine=R}

\usepackage{Sweave}

\begin{document}

\section{Conservation Analysis}
Firs we will show an example of conservation analysis in a non-model organism,
\emph{S. lycopersicon} (tomato).  An alignment of tomato, potato,
eggplant, pepper, and petunia is available at Cornell's UCSC genome browser
mirror, and can be downloaded through the table browser.

<<consAnalysis1>>=
require("rphast")

# extract the  alignment and annotation from the RPHAST package
exampleArchive <- system.file("extdata", "examples.zip", package="rphast")
unzip(exampleArchive, c("sol1.maf", "sol1.gp"))

#also define tree
tomatoTree <- "((((tomato,potato), eggplant), pepper), petunia);"

# read the alignment and give common names
align <- read.msa("sol1.maf")
names(align)
align$names <- c("tomato", "potato", "pepper", "petunia", "eggplant")

# load the features
feats <- read.gff("sol1.gp")
unique(feats$seqname)
# they are all on chr2 so rename to "tomato" to cross-reference with alignment
feats$seqname <- "tomato"

# annotate UTRs and introns
feats <- addUTRs.gff(feats)
feats <- addIntrons.gff(feats)

table(feats$feature)

# note that there are no UTRs.. are CDS and exon the same?

# pull out and sort CDS regions.
feats.cds <- sort.gff(feats[feats$feature=="CDS",])

# pull out and sort exons
feats.exon <- sort.gff(feats[feats$feature=="exon",])

# check if they are the same ... they are!
sum(feats.cds$start != feats.exon$start |
    feats.cds$end != feats.exon$end)

# so remove redundant exon features
feats <- feats[feats$feature != "exon",]

table(feats$feature)

# Now want to annotate non-coding regions.  First need to define
# chromosome boundaries

# make a feature that represents the entire chromosome
wholeChrom <- gff(seq="tomato", src=".", feature="all",
                  start=1, end=122080)

# annotate non-coding reginos
coding.feats <- feats
noncoding.feats <- inverse.gff(feats, region.bounds=wholeChrom)
noncoding.feats$feature <- "noncoding"
feats <- rbind.gff(feats, noncoding.feats)

# now extract 4d sites from alignment using annotations
align4d <- get4d.msa(align, feats)

# estimate neutral model from 4d sites
neutralMod <- phyloFit(align4d, tree=tomatoTree, subst.mod="REV")

# now run phastCons to score/predict conserved elements
pc1 <- phastCons(align, neutralMod, viterbi=TRUE)

names(pc1)

# examine the results
# the transition rates between conserved and non-conserved are here:
pc1$transition.rates

# the conserved elements are in a GFF object stored here:
dim(pc1$most.conserved)
# this shows how many bases are predicted to be conserved
coverage.gff(pc1$most.conserved)

# we get about 19.2% coverage of conserved elements without estimating rho
# (here rho was held constant at 0.3, but is only a prior)
coverage.gff(pc1$most.conserved)/coverage.gff(wholeChrom)

# the posterior probabilities for every base are here:
names(pc1$post.prob.wig)
dim(pc1$post.prob.wig)

# and the overall likelihood is here:
pc1$likelihood

# Run phastCons again, this time try to estimate the fraction of sites which
# are conserved
pcEM <- phastCons(align, neutralMod, viterbi=TRUE, estimate.rho=TRUE) 
names(pcEM)
# note this has the same elements as pc1, plus an estimate for rho
pcEM$rho

# and the likelihood is higher since we estimate rho
pcEM$likelihood

# now coverage is a bit higher, at 23%
# (note rho only defines a prior expectation for coverage)
coverage.gff(pcEM$most.conserved)/coverage.gff(wholeChrom)

# compare the results with and without --estimate-rho
coverage.gff(pcEM$most.conserved, pc1$most.conserved)
coverage.gff(pcEM$most.conserved, pc1$most.conserved, or=TRUE)
coverage.gff(pcEM$most.conserved, pc1$most.conserved, 
             not=c(FALSE, TRUE), region.bounds=wholeChrom)
coverage.gff(pcEM$most.conserved, pc1$most.conserved, 
             not=c(TRUE, FALSE), region.bounds=wholeChrom)


# now run phyloP to get base-by-base scores
p <- phyloP(neutralMod, align, method="LRT", mode="CON")

# examine these results- it is a data frame giving
# statistics for every base in the alignment
names(p)
dim(p)

# this function will pull out all the elements of
# feats, phastCons results, and phyloP results that
# are plottable
plotData <- getPlottableResults(list(feats=coding.feats,
                                     phastCons1=pc1,
                                     phastConsEM=pcEM,
                                     phyloP=p))
names(plotData)
 
# plot out the entire region
plot.rphast(plotData)

# note the warning is because phyloP has several possible statistics to plot;
# (scale, lnlratio, pval)- it chooses to plot the last of these, which is
# where the p-value is stored

# zoom in
plot.rphast(plotData, xlim=c(6.5e+04, 6.7e+04))

# need to zoom in a lot to get phyloP result resolution
plot.rphast(plotData, xlim=c(6.58e+04, 6.6e+04))


# now look a bit more at conserved elements
ce <- pc1$most.conserved
hist.gff(ce, breaks=100)

# break conserved elements into coding/noncoding:

# this returns all conserved elements that overlap with coding.feats 
# by at least 50 percent
ce.coding <- overlap.gff(ce, coding.feats, min.percent=0.5)
# and this gets the ones which overlap by less than 50 percent:
ce.noncoding <- overlap.gff(ce, coding.feats, min.percent=0.5, overlapping=FALSE)
hist.gff(ce.coding, add=TRUE, col="red", breaks=100)
hist.gff(ce.noncoding, add=TRUE, col="blue", breaks=50)
legend(c("all", "coding", "noncoding"), x="topright", inset=0.01, fill=c("white", "red", "blue"))
# so coding elements tend to be longer

# can also plot histograms of scores
hist.gff(ce, type="score", breaks=100)
hist.gff(ce.coding, type="score", add=TRUE, col="red", breaks=100)
hist.gff(ce.noncoding, type="score", add=TRUE, col="blue", breaks=50)
legend(c("all", "coding", "noncoding"), x="topright", inset=0.01, fill=c("white", "red", "blue"))
# coding elements also score much higher

# look at coverage of each annotation type by conserved element
par(mfrow=c(2, 3))
for (i in 1:2) {
  cat(dim(ce), "\n")
  annCov <- c()
  conEleComp <- c()
  conEleLen <- coverage.gff(ce)
  annFrac <- c()
  annTypes <- unique(feats$feature)
  for (anntype in annTypes) {
    annfeats <- feats[feats$feature == anntype,]
    numbase <- coverage.gff(annfeats)
    annFrac <- c(annFrac, numbase)
    numconserved <- coverage.gff(annfeats, ce)
    annCov <- c(annCov, numconserved/numbase)
    conEleComp <- c(conEleComp, numconserved/conEleLen)
  }
  col <- c("red", "blue", "green")
  barplot(annCov, names.arg=annTypes, col=col)
  pie(conEleComp, labels=annTypes, col=col, radius=1.0)
  pie(annFrac, labels=annTypes, col=col, radius=1.0)
}
mtext("rho=0.3", side=3, line=-3, outer=TRUE, cex=1.5)
mtext("rho estimated by EM", side=3, line=-27, outer=TRUE, cex=1.5)


# also take a look at consered and nonconserved trees using ape
require("ape")
cons.tree <- pcEM$tree.models$cons.mod$tree
noncons.tree <- pcEM$tree.models$noncons.mod$tree
par(mfrow=c(1,2))
plot(read.tree(text = noncons.tree))
axisPhylo()
plot(read.tree(text = cons.tree))
axisPhylo()

branchlen.tree(c(noncons.tree, cons.tree))
@ 

\section{Detection of Accelerated Regions}

The next example will go through the basic steps of detecting
accelerated evolution in a subtree.  In this case we will look
for accelerated regions in the mouse-rat subtree, and we will focus
on alignments from human chromosome 22.  The ideal way to go about this
would be to first identify conserved elements using the same procedure
as in example 1, but in a subset of the alignment which excludes the 
species of interest.  Then we can look in the full alignment at these
elements for signs of acceleration in mouse-rat.

Instead we will just use the conserved elements from the UCSC genome
browser.  They can be downloaded through the table browser for
the hg18 assembly, as well as the multiple alignment.


<<rarAnalysis1>>=
require("rphast")
elements <- read.gff("chr22-elements.bed")
unique(elements$seqname)
elements$seqname <- "hg18.chr22"  # need species name 

@  

We want to regularize the lengths of the conserved elements,
so that we do not have to worry that the significance of the tests
are confounded by length.  So we split the conserved elements
into fragments of size 100, and remove remaining fragments that
are too small
<<rarAnalysis2>>=
splitLength <- 100
splitElements <- split.gff(elements, max.length=splitLength)
splitElements <- splitElements[splitElements$end - splitElements$start + 1 == splitLength,]

@ 

Now read the neutral model.  This can also be downloaded from UCSC, or
can be estimated from four-fold degenerate sites as in the previous example.
<<rarAnalyiss3>>=

exampleArchive <- system.file("extdata", "examples.zip", package="rphast")
unzip(exampleArchive, c("placentalMammals.mod))
neutralMod <- read.tm("placentalMammals.mod")

@ 
 
Finally, read the alignment.  By using the gff argument we get an un-ordered
alignment containing sites from the conserved elements only.  For simplicity
we will use a a subset of the full species set.


<<rarAnalysis4>>=
seqnames <- c("hg18", "panTro2", "ponAbe2", "rheMac2", "mm9", "rn4", "canFam2")
align <- read.msa("/Users/melissa/rphast/chr22.maf", 
                  seqnames=seqnames, gff=elements)
@ 

Now estimate a scale for the supertree for these elements, and create a new 
``neutral model'' which is scaled by this factor.

<<<rarAnalysis5>>=

# get a version of the alignment without the foreground species
subAlign <- sub.msa(align, seqs=c("mm9", "rn4"), keep=FALSE)

superTreeMod <- phyloFit(subAlign, init.mod=neutralMod, scale.only=TRUE, no.freqs=TRUE,
                         no.rates=TRUE)
prunedTree <- prune.tree(neutralMod$tree, seqs=subAlign$names, all.but=TRUE)

prunedTreeLen <- branchlen.tree(prunedTree)
superTreeLen <- branchlen.tree(superTreeMod$tree)

superTreeScale <- superTreeLen/prunedTreeLen
superTreeScale

scaledNeutralModel <- neutralMod
scaledNeutralModel$tree <- scale.tree(neutralMod$tree, scale=superTreeScale)

# also remove species from model which are not in alignment
scaledNeutralModel$tree <- prune.tree(scaledNeutralModel$tree, 
                                      seqs=align$names, all.but=TRUE)

@ 

For these short elements with a fairly small species set, we do not necessarily
want to rely on asymptotics to calculate p-values.  Instead we will demonstrate
how p-values can be calculated using parameteric and non-parametric simulations.

First do parametric simulations using the scaledNeutralModel:

<<<rarAnalysis6>>=
nrep <- 5000

# we could simulate 5000 different MSAs but it is more efficient to simulate
# one long MSA and then split it up later
simMsa <- simulate.msa(scaledNeutralModel, nrep*splitLength)

# now we create a feature object which splits the simulated alignment into
# 5000 pieces of length 100
startIdx <- (0:(nrep-1))*splitLength + 1
feat <- gff(seqname=names.msa(simMsa)[1], src="sim", feat=".",
            start=startIdx, end=startIdx+(splitLength-1))

# now using phyloP we can calculate statistics for each individual
# feature

para.sim.results <- phyloP(scaledNeutralModel, msa=simMsa, mode="ACC",
                           gff=feat, subtree="mm9-rn4")

@ 
We can also do this nonparametrically by sampling sites with replacement
from the conserved elements:
<<<rarAnalysis7>>=
simMsa <- sample.msa(align, nrep*splitLength, replace=TRUE)
nonpara.sim.results <- phyloP(scaledNeutralModel, msa=simMsa, mode="ACC",
                              gff=feat, subtree="mm9-rn4")
@ 

Now we want to run phyloP on the real data.  To do this we need
to read an ordered version of the alignment from the MAF file, then
run phyloP on our elements:
<<<rarAnalyiss8>>=
align <- read.msa("/Users/melissa/rphast/chr22.maf",
                  seqnames=seqnames)
obs.phyloP <- phyloP(scaledNeutralModel, msa=align, mode="ACC", gff=splitElements,
                     subtree="mm9-rn4")

# free up some memory to keep R speedy
rm(align)
gc()
@ 

We can plot the distribution of likelihood ratios, as well as the 
distribution expected under chi-squared approximation:
<<<rarAnalyis9>>=
plot(density(2*obs.phyloP$lnlratio), ylab="Density", xlab="2*(likelihood ratio)")
lines(density(2*para.sim.results$lnlratio), col="blue")
lines(density(2*nonpara.sim.results$lnlratio), col="red")
curve(dchisq(x, 1), xlim=range(obs.phyloP$lnlratio), add=TRUE, lty=2)
legend(x="topright", inset=0.05, c("obs", "para sim", "non-para sim", "chi-square"), col=c("black", "blue", "red"),
       lty=c(1,1,1,2))
@ 

Calculate p-values for the observed for each simulation set:
<<<rarAnalysis10>>=

empirical.pval <- function(x, dist) {
  sum(x > dist)/length(dist)
}

para.pval <- sapply(obs.phyloP$lnlratio, empirical.pval, para.sim.results$lnlratio)
nonpara.pval <- sapply(obs.phyloP$lnlratio, empirical.pval, nonpara.sim.results$lnlratio)
hist(para.pval, breaks=100)
hist(nonpara.pval, breaks=100, col="red", add=TRUE)

@ 
We can use 5\% FDR to correct for multiple testing:
<<rarAnalysis11>>=

require("multtest")
# which method to use?
para.fdr <- mt.rawp2adjp(para.pval, proc="BH")
para.fdr <- para.fdr$adjp[order(para.fdr$index),2]
nonpara.fdr <- mt.rawp2adjp(nonpara.pval, proc="BH")
nonpara.fdr <- nonpara.fdr$adjp[order(nonpara.fdr$index),2]

sum(para.fdr < 0.05)

# this gets the indices of elements with adjusted p-values < 0.05
sigIdx <- unique(c(which(para.fdr < 0.05),
                   which(nonpara.fdr < 0.05)))
length(sigIdx)
sigFeats <- splitElements[sigIdx,]
sigFeats$feature <- "RAR"  # for rodent-accelerated region
coverage.gff(sigFeats)
plot.rphast(list(RAR=sigFeats, Conserved.elements=elements))

# can print out a features file that can be displayed on browser
write.gff("RAR.gff", sigFeats)

@ 


\section {Phylo-HMMs}

In the last example we are going to create a custom phylo-HMM and try to use
it to detect transcription factor binding sites. 

We will once again use the multiple alignments available on UCSC, as well 
as the neutral model from the second example.  The rphast package comes
with a set of multiple alignments for identified NRSF binding sites,
as well as a GFF describing their genomic positions.  We will use these
to build the phylo-HMM.
<<phyloHmm1>>=
require("rphast")
# lets use a subset of the full species
seqnames <- c("hg18", "panTro2", "ponAbe2", "rheMac2", "equCab2", "canFam2", "dasNov2", "mm9", "rn4",
              "galGal3", "xenTro2")
neutralMod <- read.tm("placentalMammals.mod")
neutralMod$tree <- prune.tree(neutralMod$tree, seqs=seqnames, all.but=TRUE)

# get the NRSF maf files from rphast
unzip(system.file("extdata", "NRSF.zip", package="rphast"))
mafFiles <- list.files("NRSF", pattern="*.maf", full.names=TRUE)
nrsfNames <- basename(mafFiles)
nrsfNames <- substr(nrsfNames, 1, nchar(nrsfNames)-4) #remove .maf from end of names
nrsfSites <- read.gff("NRSF/NRSF.gff")
motifLen <- 21   # this is the length of the NRSF binding site
msaList <- list()
for (i in 1:length(mafFiles)) {
  smallMsa <- read.msa(mafFiles[i], seqnames=seqnames)
  
  # remove gaps from hg18 so that alignments have exactly 21 columns
  smallMsa <- strip.gaps.msa(smallMsa)
  
  # remove offset so that columns are numbered 1..21 instead of using genomic coords
  smallMsa$offset <- 0 
  
  # get the feature corresponding to this alignment
  feat <- nrsfSites[which(nrsfSites$feature == nrsfNames[i]),]
  
  # reverse the alignment if the binding site is on the minus strand
  if (feat$strand == "-") 
    smallMsa <- reverse.complement(smallMsa)
  if (ncol.msa(smallMsa) != motifLen)
    cat("wrong number of columns in ", nrsfNames[i], "\n")
  msaList[[nrsfNames[i]]] <- smallMsa
}
# now concatenate all alignments
aggMsa <- concat.msa(msaList)
@ 

Now we we have a concatenated alignment of 52 different 21-bp binding sites.  We want
to create a feature set so that each position of the alignment has its own feature.  
Then we can estimate models for each position using phyloFit.  Since we do not have
very much data, we will only estimate a scale factor for each position.

<<phyloHmm2>>=
feats <- gff(seqname="hg18", src=as.character(sapply(nrsfNames, rep, motifLen)),
             feature=rep(sprintf("site.%i", 1:motifLen), length(mafFiles)),
             start=1:(motifLen*length(mafFiles)),
             end=2:(motifLen*length(mafFiles)+1))
mods <- phyloFit(aggMsa, init.mod=neutralMod, no.rates=TRUE, gff=feats,
                 scale.only=TRUE, ninf.sites=10)
# the warning about skipping category 0 just means that there are no sites
# which don't belong to any category so it won't return a model for that

length(mods)

# compute the scale factors for each position
trees <- character()
for (i in 1:length(mods)) trees[i] <- mods[[i]]$tree
scale.factors <- branchlen.tree(trees)/branchlen.tree(neutralMod$tree)

# this plot is a complete mess for now but seqLogo seems to write to some
# weird device; there's no way to see the two plots next to each other within R
# is there another pacakge for plotting logos? 
require("seqLogo")
m <- read.table("NRSF/NRSF.mtf")
barplot(scale.factors, density=1)
pwm <- makePWM(t(m))
seqLogo(pwm)
barplot(scale.factors, add=TRUE, density=1)
abline(h=1,lty=2)

@ 

Now we are going to make a 23-state phylo-HMM.  The 23 states are the 21
states for each position in the motif, plus a conserved and a non-conserved state.
We can then use phastCons to find possible binding sites using this phylo-HMM.
We wil use some parameters from the phastCons track on UCSC to define the 
phylo-HMM.

<<phyloHmm3>>=
mods[["neutral"]] <- neutralMod
mods[["conserved"]] <- neutralMod
mods[["conserved"]]$tree <- scale.tree(neutralMod$tree, 0.3)

# define the transition matrix between states
# lambda is the rate of transition to the motif 
get.trans.mat <- function(lambda, state.names, motifLen) {
  trans.mat <- matrix(0, nrow=length(state.names), ncol=length(state.names),
                      dimnames=list(state.names, state.names))
  mu <- 1/45  # 45 is the expected length of conserved elements
  nu <- (mu*0.3)/(1.0-0.3)   #0.3 is the target coverage of conserved elements
  trans.mat["conserved", "neutral"] <- mu
  trans.mat["neutral", "conserved"] <- nu
  trans.mat["conserved", "site.1"] <- lambda
  trans.mat["neutral", "site.1"] <- lambda
  lastSite <- sprintf("site.%i", motifLen)
  trans.mat[lastSite, "conserved"] <- 0.5
  trans.mat[lastSite, "neutral"] <- 0.5
  trans.mat["conserved", "conserved"] <- 1 - lambda - mu
  trans.mat["neutral", "neutral"] <- 1 - lambda - nu
  for (i in 1:(motifLen-1)) 
    trans.mat[sprintf("site.%i", i), sprintf("site.%i", i+1)] <- 1
  trans.mat
}

# would like to show a plot but haven't found a good package yet
# have tried Rgraphviz, but it requires some external software (GraphViz) 
# which makes it problematic for the vignette.
# Also looked at dagR but I don't think it can make the kind of plot we want,
# and is also quite complicated - would take a half dozen commands at least

# this is the rate of transition to motif states
lambda <- 0.00001
trans.mat <- get.trans.mat(lambda, names(mods), motifLen)
# need equilibrium frequencies for the HMM
eq.freq <- numeric(nrow(trans.mat))
for (i in 1:nrow(trans.mat)) {
  if (names(mods)[i] == "conserved") {
    eq.freq[i] <- 0.3
  } else if (names(mods)[i] == "neutral") {
    eq.freq[i] <- 0.6999
  } else {
    eq.freq[i] <- 0.0001/motifLen
  }
}
sum(eq.freq)  #make sure sums to 1

# now create the HMM
nrsf.hmm <- hmm(trans.mat, eq.freq, begin.freq=eq.freq)

# now we are going to test the HMM on a 1 MB region of chromosome 19 which has
# several known NRSF sites.  We are cheating here though because these sites
# were used to define the HMM.  Maybe we should do something else?
align <- read.msa("/Users/melissa/rphast/chr19.59000000-60000000.maf",
                  seqnames=seqnames)
align <- strip.gaps.msa(align)
pc <- phastCons(msa=align, mod=mods, hmm=nrsf.hmm, viterbi=TRUE,
                states=sprintf("site.%i", 1:motifLen),
                reflect.strand=c("neutral", "conserved"))
knownSites <- nrsfSites[nrsfSites$seqname=="hg18.chr19",]
plotL <- getPlottableResults(list(NRSFSites=knownSites,
                                  phastConsResults=pc))
plot.rphast(plotL)

# zoom in on the 9 sites we expected to find
par(mfrow=c(3, 3))
for (i in 1:nrow(knownSites)) {
  start <- knownSites[i,]$start
  end <- knownSites[i,]$end
  plot.rphast(plotL, xlim=c(start-100, end+100))
}

# lets just see if this has something to do with the pivot.states
pcPlus <- phastCons(msa=align, mod=mods, hmm=nrsf.hmm, viterbi=TRUE,
                    states=sprintf("site.%i", 1:motifLen))
plotL <- getPlottableResults(list(NRSFSites=knownSites,
                                  phastConsResultsPlus=pcPlus))
plot.rphast(plotL)

@ 

\end{document}
